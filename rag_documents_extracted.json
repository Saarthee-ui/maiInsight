{
  "PROCESS.docx": {
    "path": "rag_documents\\PROCESS.docx",
    "content": "AI Analytics Agent RAG\n\nHow the platform functions?\n\nYou are an AI analytics assistant that helps users transform data to generate reports, analysis and actionable insights. When the admin user logs in to build a analytics transformation, he or she will follow the following steps:\n\nBuild\n\nExtract\n\nTransform\n\nVisualize\n\nAnalyze\n\nThis document helps put down the functioning of the Build Phase agents\n\nBuild Stage\n\nbuildRetrieval Agent:\n\nInitiate the conversation with the user asking what the user is trying to accomplish.\n\nPresent a short summary to the user with hints such as:\n\n‚ÄúCreate a new transformation flow from Sales and Customer Database? ‚ÄúCreate Performance Monitoring Report?‚Äù\n\n‚ÄúSet up a data extraction for full refresh in the existing report?‚Äù\n\nWould you like me to do that?‚Äù\n\nAsk the user the following in sequence, confirming each step:\n\n‚ÄúPlease confirm which database(s) I should connect to.‚Äù\n\nMake hints from the database schema details and submit for User confirmation. For example, Sales and Customer means data sitting in Sales and Customer Database\n\n‚ÄúWhat transformation name should I use? I‚Äôll create a folder for it.‚Äù Suggest AI generated hints like PERFORMANCE MONITORING, SALES REPORT\n\n‚ÄúCan you share or confirm the connection details (host, user, credentials)? I‚Äôll store them securely.‚Äù\n\nValidate each input (non-empty, plausible) and echo back for confirmation.\n\nOnce all essentials are gathered, summarize the setup:\n‚ÄúI‚Äôll connect to {database}, create a folder named {transformation_name}, and use {connection_type}. Shall I proceed?‚Äù\n\nSave to buildRetrieval once user approves the output post user confirmation by returning the JSON file\n\nTwo buttons popup\n\nMake Connections and Make Folder\n\nWhen you click Make Connections, buildActionConnectDB kicks in and same thing with other. Output at his stage shows folder listing and connections status\n\nbuildActionFolder\n\nFetch information from buildRetrieverdatabase and run pregenerated code to create folder and make folder\n\nbuildActionConnectDB\n\nFetch information from buildRetriverdatabase and run pregenerated code to set up new connect\n\nAnalytics Process expected by AI to perform assisted with human inputs\n\nBuild\n\nExtract\n\nTransform\n\nVisualize\n\nAnalyze\n\nHere is the summary of each phase:\n\nBuild\n\nConversationally AI initiates prompt to fetch Process Initiation.  Desired Information is Data base Names, Connection, Organization (sales , marketing , finance, CX, HR, Technology etc) and Connection Details restricting password intakes. If users wanders away in a conversation, politely mention the goal of build phase and we can visit these requirements in the later phases. Wherever Agent can predict the answers hint the user. Finally capture all requirement in one go and ask user to confirm. This information once verified will be saved. Actions to create connections and folder and human validation will be the success of this phase\n\nextract:\n\nSeeking data pull inputs to generate code for pull. Once code is verified save and vault it. Execute the code making sure data trails are maintained. Make arrangements for the code to have both full and incremental capability.\n\nSuccess of this is verified data pull code. And Data pulled and verified by use.\n\nTransform\n\nTransform has three phases:\n\nBronze-copy extracted with the right naming convention, create dictionaries and perform data quality checks\n\nSilver-Breakdown the data, create reference which is repeating and is not impacted by time\n\nGold- Facts and dimension creation\n\nSuccess if human verified code. Execution of code to generate data sets in three layers\n\nVisualize:\n\nUpload reports to generate react code. Or use a promot to build a report from scratch. In future have the option of bulk upload of existing report which can be migrated to react/java, power BI , Tableau. Prompt will be used to make changes. Once human verified, views with code vaulted\n\nAnalyze\n\nCreate template for adhoc and repeating analyses\n\nContext for each stage",
    "length": 3991
  },
  "RAG 1 DOMAIN KNOWLEDGE.docx": {
    "path": "rag_documents\\RAG 1 DOMAIN KNOWLEDGE.docx",
    "content": "[TD001] Telecom Network Types and Use-cases\n\nTelecom networks include mobile, fixed-line, fibre, and wholesale infrastructures.\n\nFor analytics, these networks produce datasets such as Call Detail Records (CDRs), data session logs, broadband throughput, and latency reports.\n\nUnderstanding network types supports analytics models for churn prediction, throughput optimization, NPS tracking, and cost-to-serve analysis.\n\n[TD002] Customer Usage Metrics in Telecom\n\nCommon telecom usage metrics: ARPU (Average Revenue Per User), MOU (Minutes of Use), GB per user, Churn Rate, Activation Rate, Roaming Revenue.\n\nFor analytics transformation, standardize units (bytes to GB), normalize timestamps, and aggregate by subscriber, plan, or region.\n\nTypical AI features: usage_gb_30d, churn_flag, roaming_spend_change.\n\n[TD003] Bronze-Silver-Gold Data Architecture\n\nBronze layer: raw CDRs, recharge, billing, and network logs.\n\nSilver layer: cleaned subscriber usage aggregated by day or month.\n\nGold layer: semantic marts such as Customer360, Usage360, NetworkKPI.\n\nTransformation logic must include deduplication, MSISDN/IMSI resolution, timezone normalization, and lineage tracking.\n\n[TD004] AI Use-cases in Telecom\n\nAI drives churn prediction, Next Best Offer (NBO), anomaly detection in network logs, CLV forecasting, and fraud detection.\n\nSuccessful implementation requires well-structured time-series data, customer features, event logs, and compliance with governance rules.\n\nAll AI workflows must include explainability, data provenance, and model drift monitoring.\n\n[TD005] Incremental Merge and Delta Logic\n\nTelecom datasets are huge; incremental loads are key.\n\nUse watermark columns (last_updated_ts), partition by date or region, and implement SQL MERGE INTO or UPSERT logic.\n\nTrack schema evolution and maintain deduplication and validation during ingestion.\n\n[TD006] Telecom Customer Segmentation\n\nSegments are built on usage volume, churn risk, plan type (prepaid/postpaid), data vs voice preference, and region.\n\nJoin CDR, billing, marketing, and support data to build feature-rich segments.\n\nThese feed marketing campaigns, cross-sell strategies, and personalization engines.\n\n[TD007] Data Quality Challenges\n\nMajor issues: inconsistent identifiers (MSISDN/IMSI), duplicates, timezone misalignment, missing fields, event lag.\n\nSolutions: data quality rules, schema validation, anomaly detection, correction workflows, and lineage visualization dashboards.\n\n[TD008] Governance and Compliance\n\nTelecom analytics must meet GDPR and local telecom regulatory requirements.\n\nEnsure data masking (for MSISDN), lineage tracking, and controlled access via role-based permissions.\n\nAI governance should include explainability, approval workflows, and audit trails.\n\n[TD009] Semantic Layer for Insights\n\nA semantic layer converts complex schemas into business entities such as Customer360, Usage360, PlanPerformance, and NetworkHealth.\n\nDefine consistent metrics (ARPU_30d, churn_score, CLV), and expose via BI tools or APIs.\n\nStandardized naming and metric definitions reduce duplication and increase self-service adoption.\n\n[TD010] Time-Series Analytics\n\nNetwork operations data (latency, jitter, throughput, drop-rate, cell load) is inherently time-series.\n\nEnable sliding-window computations (15-minute intervals), anomaly detection, and forecasting.\n\nPartition and down-sample for scalability; integrate usage and network data for holistic performance analytics.\n\n[TD011] Predictive Maintenance and Fault Analytics\n\nAI-based predictive models detect anomalies before service outages.\n\nIntegrate network telemetry, alarms, and historical fault tickets to predict and prevent failures.\n\nOutput actionable insights for field teams and optimize resource scheduling.\n\n[TD012] Revenue Assurance and Fraud Detection\n\nMonitor discrepancies between billing, CDRs, and partner settlements.\n\nUse anomaly detection and correlation models to flag leakage or fraud patterns.\n\nAutomate investigation workflows with explainable AI triggers.\n\n[TD013] Customer Experience Analytics\n\nCombine network quality metrics (QoS, QoE) with customer feedback (NPS, complaints).\n\nAI models classify experience tiers and identify top drivers of dissatisfaction.\n\nOutput: proactive campaigns, network prioritization, and product redesigns.\n\n[TD014] Data Transformation Workflows\n\nTypical telecom data pipelines: ingestion ‚Üí cleaning ‚Üí enrichment ‚Üí standardization ‚Üí aggregation ‚Üí semantic modeling ‚Üí AI features.\n\nAutomation rules: use AI to suggest joins, mapping logic, and field transformations based on metadata similarity.\n\n[TD015] 5G Analytics Use-cases\n\nWith 5G, data granularity increases exponentially.\n\nUse cases: network slicing optimization, IoT device monitoring, real-time usage prediction, latency anomaly detection.\n\nIntegrate edge analytics with centralized AI orchestration for near real-time insight.\n\n[TD016] KPI Framework\n\nKey telecom KPIs: ARPU, Churn Rate, Customer Lifetime Value (CLV), Network Availability, First Call Resolution (FCR), NPS.\n\nDefine each KPI in the semantic layer and enforce consistency across dashboards and AI models.\n\n[TD017] Monetization and Pricing Analytics\n\nAI optimizes tariff plans, discount offers, and bundle recommendations.\n\nUse historical spend, elasticity modeling, and micro-segmentation to maximize revenue while maintaining retention.\n\n[TD018] Data Catalog and Metadata Management\n\nA governed catalog ensures discoverability and traceability.\n\nCapture lineage, ownership, schema versions, and transformation logs for every data asset.\n\nEnable search via metadata tagging and vector embeddings.\n\n[TD019] ETL Optimization for Telecom\n\nUse parallel processing, late binding views, and partition pruning for high-volume telecom data.\n\nIntegrate orchestration frameworks (Airflow, Prefect) with AI assistance for scheduling and error recovery.\n\n[TD020] AI Ethics and Responsible Use\n\nEnsure fairness in offer recommendations and credit scoring.\n\nAudit AI bias, monitor drift, and document model logic.\n\nAdopt transparent feedback mechanisms and human-in-the-loop approval.",
    "length": 6099
  },
  "RAG 3 SYSTEM ARCHITECTURE.docx": {
    "path": "rag_documents\\RAG 3 SYSTEM ARCHITECTURE.docx",
    "content": "[AP001] Overview of AI-Assisted Analytics Process\n\nThe AI analytics process consists of five primary phases:\n\n1. Build\n\n2. Extract\n\n3. Transform\n\n4. Visualize\n\n5. Analyze\n\nEach phase is semi-automated by AI with human-in-the-loop validation and governance, ensuring efficiency, quality, and control.\n\n[AP002] Phase 1: Build\n\nThe AI initiates the process conversationally through prompts that gather essential setup information such as:\n\n- Database names\n\n- Connection details (excluding passwords)\n\n- Business organization domain (sales, marketing, finance, CX, HR, technology, etc.)\n\nIf the user diverges from the conversation, the AI politely redirects focus to the goal of the build phase.\n\nWhenever possible, the AI predicts missing inputs and suggests them to the user for validation.\n\nOnce all requirements are captured and confirmed, the AI:\n\n- Creates connections\n\n- Initializes project folders\n\n- Waits for human validation to confirm completion\n\nSuccess Criteria: Human validation of connection and environment setup.\n\n[AP003] Phase 2: Extract\n\nThe AI collects input parameters required for data extraction and generates code for pulling data from defined connections.\n\nThe generated code supports both full and incremental loads, with logging to maintain data trails.\n\nOnce the code is verified and approved, it is:\n\n- Saved securely in the vault\n\n- Executed to pull the data\n\nSuccess Criteria: Verified and executed extraction code; validated data pull by user.\n\n[AP004] Phase 3: Transform\n\nThe transformation phase occurs in three sub-layers:\n\n- **Bronze:** Copies the extracted data with correct naming conventions, builds data dictionaries, and performs data quality checks.\n\n- **Silver:** Decomposes data, isolates repeating reference entities, and structures them independent of time-based changes.\n\n- **Gold:** Builds fact and dimension tables for semantic and analytical purposes.\n\nThe AI assists in code generation for each transformation layer, enforcing conventions and data lineage.\n\nSuccess Criteria: Human-verified transformation code and successful execution producing datasets across all three layers.\n\n[AP005] Phase 4: Visualize\n\nThe AI uploads or generates reports and visualization components:\n\n- Generates React-based visualization code or supports Power BI/Tableau formats.\n\n- Enables prompts to modify or create new reports from scratch.\n\n- Future support: bulk upload of existing reports to migrate to React/Java/Power BI/Tableau.\n\nAfter human validation, the visualizations and underlying code are vaulted.\n\nSuccess Criteria: Verified visualizations and reusable code templates.\n\n[AP006] Phase 5: Analyze\n\nThe AI supports ad hoc and recurring analyses through predefined templates:\n\n- Ad hoc: User-guided, conversational analyses for immediate insights.\n\n- Repeating: Automated execution and delivery of recurring insights based on pre-approved templates.\n\nThe agent identifies analytical intent, fetches relevant data, and generates structured, explainable results for review.\n\nSuccess Criteria: Verified analytical outputs and reusable analysis templates.\n\n[AP007] Human-in-the-Loop Governance\n\nEach phase requires human approval before proceeding to the next step.\n\nThe AI ensures:\n\n- Traceability of actions\n\n- Storage of verified code in the vault\n\n- Versioning and lineage for repeatability\n\nThe final goal is to combine AI efficiency with human oversight to create a secure, auditable analytics workflow.\n\n[AP008] Process Automation and Future Enhancements\n\nFuture iterations may include:\n\n- Automated metadata capture across all stages\n\n- AI recommendations for code optimization and performance tuning\n\n- Seamless integration of analytics lifecycle with orchestration tools (LangChain, Airflow)\n\n- Continuous learning based on user corrections and validations to enhance prediction accuracy.",
    "length": 3835
  },
  "RAG2 CONTEXTUAL MEMORY.docx": {
    "path": "rag_documents\\RAG2 CONTEXTUAL MEMORY.docx",
    "content": "[BSG001] Optimizing Bronze‚ÄìSilver‚ÄìGold Architecture\n\nModern data architectures often follow a layered pattern:\n\n- Bronze: Raw, untransformed data from source systems.\n\n- Silver: Cleaned and standardized datasets ready for analytics.\n\n- Gold: Curated, pre-aggregated, business-ready data marts.\n\nFor efficiency, it is not always cost-effective to build the Gold layer upfront. A selective approach builds Gold only for high-demand analytical areas or heavy queries identified via monitoring. This ensures cost and performance optimization in cloud environments where frequent queries on Silver can be expensive.\n\n[BSG002] Adaptive Gold Layer Strategy\n\nThe goal is to avoid unnecessary Gold layer creation and migration of thousands of existing dashboards. Instead, allow business users to explore Silver data using semantic search, AI guidance, and contextual metadata ‚Äî without deep knowledge of the underlying schema. Gold models should be generated only when data usage and query complexity justify it, ensuring performance without overengineering.\n\n[BSG003] Monitoring Query Patterns for Gold Layer Creation\n\nAutomate the detection of query frequency and computational cost on Silver. Use AI-based monitoring to flag repetitive or high-cost queries and automatically propose a Gold dataset for those cases. This supports dynamic Gold model creation that scales with business usage patterns and reduces manual intervention.\n\n[BSG004] Complex Transformations Between Silver and Gold\n\nIn telecom and other industries, transformations from Silver to Gold are often nontrivial. Metrics such as ARPU (Average Revenue Per User) cannot be directly aggregated; they require product-based and service-based calculations that differ across customers. Transformation logic should support parameterized calculations, reusable templates, and domain-specific functions to derive KPIs dynamically.\n\n[BSG005] Business Questions for Gold Layer Use\n\nGold data should support answering key business questions efficiently, including:\n\n- Revenue and usage metrics per customer segment\n\n- Churn and retention drivers\n\n- Cross-product performance and profitability\n\n- Campaign attribution and offer effectiveness\n\nGold datasets should be shaped around these questions and be explainable, traceable, and auditable.\n\n[BSG006] Silver Layer Automation from ODS (Operational Data Store)\n\nAutomating the Silver layer involves reading structured data from the Bronze or ODS layer and proposing a normalized target model following Data Vault 2.0 principles. The process should:\n\n- Identify source entities and relationships\n\n- Propose hub, link, and satellite structures\n\n- Generate incremental load logic from Bronze\n\n- Create DDL and ETL code automatically\n\nThis automation reduces engineering effort and ensures consistency in data modeling across projects.\n\n[BSG007] Incremental Loading from Bronze to Silver\n\nAI-driven data pipelines should automatically determine delta logic using timestamps, version columns, or hash comparisons. Incremental loads minimize compute costs and align with continuous ingestion patterns common in telecom and enterprise analytics.\n\n[BSG008] Semantic Exploration Without Gold Layer\n\nBusiness users should be able to explore data without knowing schema details or underlying storage layers. AI should translate natural-language queries into SQL across Silver datasets using metadata and relationships. This semantic capability bridges the gap between raw data and decision-ready insights, deferring the need for pre-aggregated Gold datasets until clearly justified.\n\n[BSG009] AI-Driven Code Generation for Data Vault Compliance\n\nWhen ingesting new data from Bronze to Silver, AI can generate compliant Data Vault structures, incremental load SQL, and documentation. The RAG agent should recall prior models to maintain naming standards, keys, and lineage, ensuring enterprise-level governance.\n\n[BSG010] Business-Driven Gold Creation\n\nAI should recommend Gold datasets based on business demand signals, such as frequently accessed KPIs or repetitive transformations. The system should balance cost, performance, and governance, generating Gold marts only where necessary and aligning with performance SLAs.",
    "length": 4212
  },
  "RAG2b DATABASE SCHEMAS.docx": {
    "path": "rag_documents\\RAG2b DATABASE SCHEMAS.docx",
    "content": "[MDL001] Medallion Architecture Overview\n\nThe Medallion architecture enables scalable, modular data engineering with three distinct layers:\n\n- ü•â Bronze Layer: Source-aligned raw data.\n\n- ü•à Silver Layer: Business-aligned normalized model (Data Vault).\n\n- ü•á Gold Layer: Analytics-ready dimensional model.\n\nThis design supports lineage, traceability, and efficient transformation across the data lifecycle.\n\n[MDL002] Bronze Layer ‚Äì Source-Aligned, CDC-Based Data Replica\n\nPurpose: Maintain a near-real-time replica of source systems, including CDC (insert/update/delete) transactions.\n\nEnsures traceability and auditability of raw business data before transformation.\n\nKey Entities:\n\n- CUSTOMER_BZ: Customer source data (CUSTOMER_ID, CUSTOMER_NAME, SEGMENT_CODE, CREATED_AT, UPDATED_AT)\n\n- SEGMENT_BZ: Reference data for customer segmentation (SEGMENT_CODE, SEGMENT_NAME, DESCRIPTION)\n\n- ORDER_BZ: Order headers (ORDER_ID, CUSTOMER_ID, CHANNEL_ID, ORDER_DATE, STATUS, TOTAL_AMOUNT)\n\n- ORDER_DETAIL_BZ: Line-level order details (ORDER_DETAIL_ID, ORDER_ID, PRODUCT_ID, QUANTITY, PRICE, DISCOUNT, TOTAL_LINE_AMOUNT)\n\n- PRODUCT_BZ: Product and category reference data (PRODUCT_ID, PRODUCT_NAME, CATEGORY_ID, CATEGORY_NAME, TYPE, PRICE)\n\n- CHANNEL_BZ: Sales channel hierarchy (CHANNEL_ID, CHANNEL_NAME, CHANNEL_TYPE, PARENT_CHANNEL_ID)\n\nCharacteristics:\n\n- Maintains historical CDC transactions.\n\n- 1:1 mapping with source systems.\n\n- Minimal transformation, mainly metadata enrichment.\n\n- Continuous loading via Snowpipe or streaming.\n\nSuccess Criteria: Fully auditable raw layer with CDC logs.\n\n[MDL003] Silver Layer ‚Äì Business-Aligned Data Vault Model\n\nPurpose: Normalize and historize data for consistent, source-independent truth.\n\nSupports versioning, lineage, and traceability.\n\nCore Hubs:\n\n- HUB_CUSTOMER (CUSTOMER_ID): Unique customer\n\n- HUB_ORDER (ORDER_ID): Unique order\n\n- HUB_ORDER_DETAIL (ORDER_DETAIL_ID): Unique order line\n\n- HUB_PRODUCT (PRODUCT_ID): Unique product\n\n- HUB_CHANNEL (CHANNEL_ID): Unique sales channel\n\n- HUB_SEGMENT (SEGMENT_CODE): Unique segment\n\nSatellites:\n\n- SAT_CUSTOMER_ATTR ‚Üí HUB_CUSTOMER: Attributes and updates (CUSTOMER_NAME, REGION, CREATED_AT, UPDATED_AT)\n\n- SAT_ORDER_STATUS ‚Üí HUB_ORDER: Order status, date, amount\n\n- SAT_ORDER_DETAIL_ATTR ‚Üí HUB_ORDER_DETAIL: PRODUCT_ID, QUANTITY, PRICE, TOTAL_LINE_AMOUNT\n\n- SAT_PRODUCT_ATTR ‚Üí HUB_PRODUCT: PRODUCT_NAME, CATEGORY_ID, PRICE\n\n- SAT_CHANNEL_ATTR ‚Üí HUB_CHANNEL: CHANNEL_NAME, CHANNEL_TYPE, PARENT_CHANNEL_ID\n\n- SAT_SEGMENT_ATTR ‚Üí HUB_SEGMENT: SEGMENT_NAME, DESCRIPTION\n\nLinks:\n\n- LINK_CUSTOMER_ORDER: CUSTOMER ‚Üí ORDER\n\n- LINK_ORDER_ORDERDETAIL: ORDER ‚Üí ORDER_DETAIL\n\n- LINK_PRODUCT_CATEGORY: PRODUCT ‚Üí CATEGORY\n\n- LINK_CHANNEL_HIERARCHY: CHANNEL ‚Üí PARENT_CHANNEL\n\n- LINK_CUSTOMER_SEGMENT: CUSTOMER ‚Üí SEGMENT\n\nCharacteristics:\n\n- Enables historization (effective dates in satellites)\n\n- Handles slowly changing attributes (SCD Type 2)\n\n- Provides consistent lineage across all hubs\n\n- Loaded daily from Bronze layer\n\nSuccess Criteria: Validated, versioned, normalized Silver model with audit-ready lineage.\n\n[MDL004] Gold Layer ‚Äì Dimensional / Analytics Model\n\nPurpose: Provide analytics-optimized schema for reporting and AI-driven insights.\n\nFact Table:\n\n- FACT_ORDER: One row per order (Factless Fact)\n\nColumns: ORDER_ID, CUSTOMER_ID, CHANNEL_ID, SEGMENT_ID, PRODUCT_CATEGORY_ID, ORDER_STATUS_ID, ORDER_DATE_ID, TOTAL_AMOUNT, PRODUCT_COUNT, SERVICE_COUNT, AVG_PRICE_PER_ITEM\n\nDimension Tables:\n\n- DIM_CUSTOMER (CUSTOMER_ID): CUSTOMER_NAME, REGION, AGE_GROUP, TENURE_MONTHS, SEGMENT_ID\n\n- DIM_SEGMENT (SEGMENT_ID): SEGMENT_CODE, SEGMENT_NAME, DESCRIPTION\n\n- DIM_PRODUCT_CATEGORY (PRODUCT_CATEGORY_ID): CATEGORY_NAME, CATEGORY_TYPE, CATEGORY_GROUP\n\n- DIM_CHANNEL (CHANNEL_ID): CHANNEL_NAME, CHANNEL_TYPE, PARENT_CHANNEL_ID, CHANNEL_LEVEL\n\n- DIM_ORDER_STATUS (ORDER_STATUS_ID): STATUS_CODE, STATUS_LABEL, STATUS_GROUP\n\n- DIM_TIME (TIME_ID): DATE, WEEK, MONTH, QUARTER, YEAR, WEEKDAY_FLAG\n\nCharacteristics:\n\n- Aggregated and conformed dimensions for analytics.\n\n- Optimized for Power BI, Tableau, React, and AI query generation.\n\n- Built selectively based on cost‚Äìperformance balance.\n\nSuccess Criteria: Analytical performance and scalability with verified dimensional joins.\n\n[MDL005] Business Questions Supported by the Gold Layer\n\nüìä Sales Performance\n\n- Total sales amount per month and per channel\n\n- Orders by product category and segment\n\n- Highest-revenue channels\n\n- Average order value by category\n\n- Completed vs canceled orders per month\n\nüë• Customer Insights\n\n- Top-revenue customer segments\n\n- Active customer growth trend (MoM)\n\n- Average orders per customer by segment\n\n- Regional or segment-based growth\n\n- Churn risk inferred from order frequency decline\n\nüõí Product & Service Analysis\n\n- Top 10 product categories by revenue and order count\n\n- Products with highest average price per item\n\n- Ratio of service to product orders\n\n- Cross-sell ratio between products and services\n\n- Seasonal product trends\n\nüè™ Channel & Sales Efficiency\n\n- Best-performing channels by conversion rate\n\n- Volume variation across channel hierarchy\n\n- Channel growth trends\n\n- Average order value by channel type\n\n‚è≥ Time & Trend Analysis\n\n- Revenue trend (QoQ, YoY)\n\n- Peak order days of week\n\n- Growth rate per channel or segment\n\n- Cancellation pattern by lifecycle stage\n\n[MDL006] AI-Generated Insights Examples\n\n- ‚ÄúOnline channel sales grew by 12% QoQ, mainly driven by Segment A customers ordering premium products.‚Äù\n\n- ‚ÄúRetail channel experienced a 10% drop in volume correlated with fewer service bundle sales.‚Äù\n\n- ‚ÄúSegment B customers show a 20% increase in cross-category purchases.‚Äù\n\nThese insights can be generated automatically by LLMs or analytics bots using the Gold Layer schema.\n\n[MDL007] Data Flow Summary\n\nBronze ‚Üí Silver:\n\n- Continuous ingestion, CDC-based raw replication.\n\n- AI monitors schema and maps to hubs and satellites.\n\nSilver ‚Üí Gold:\n\n- Business-driven aggregation and dimensional modeling.\n\n- AI determines which gold models to create based on usage and performance analytics.\n\n[MDL008] Governance & Quality\n\n- Lineage captured from Bronze through Gold.\n\n- Human validation at each layer.\n\n- Incremental loads validated via timestamps.\n\n- Schema evolution tracked in metadata vault.\n\nSuccess Criteria: Verified, governed pipeline supporting automated analytics and AI report generation.",
    "length": 6393
  },
  "RAG4 CONTEXT.docx": {
    "path": "rag_documents\\RAG4 CONTEXT.docx",
    "content": "Error reading rag_documents\\RAG4 CONTEXT.docx: File is not a zip file",
    "length": 69
  }
}